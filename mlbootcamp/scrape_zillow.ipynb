{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zillow Web Scraper\n",
    "A simple web scraper written using scrapy.  \n",
    "Based off of https://www.scrapehero.com/how-to-scrape-real-estate-listings-on-zillow-com-using-python-and-lxml/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install lxml requests unicodecsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lxml import html\n",
    "import requests\n",
    "import unicodecsv as csv\n",
    "import argparse\n",
    "\n",
    "# List of San Francsisco zip codes to scrape\n",
    "SF_ZIPCODES = [94102,\n",
    "             94104,\n",
    "             94103,\n",
    "             94105,\n",
    "             94108,\n",
    "             94107,\n",
    "             94110,\n",
    "             94109,\n",
    "             94112,\n",
    "             94111,\n",
    "             94115,\n",
    "             94114,\n",
    "             94117,\n",
    "             94116,\n",
    "             94118,\n",
    "             94121,\n",
    "             94123,\n",
    "             94122,\n",
    "             94124,\n",
    "             94127,\n",
    "             94126,\n",
    "             94129,\n",
    "             94131,\n",
    "             94133,\n",
    "             94132,\n",
    "             94134,\n",
    "             94139,\n",
    "             94143,\n",
    "             94146,\n",
    "             94151,\n",
    "             94159,\n",
    "             94158,\n",
    "             94188,\n",
    "             94177]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(zipcode: str, filter: str = None):\n",
    "    if filter == \"newest\":\n",
    "        url = \"https://www.zillow.com/homes/for_sale/{0}/0_singlestory/days_sort\".format(zipcode)\n",
    "    elif filter == \"cheapest\":\n",
    "        url = \"https://www.zillow.com/homes/for_sale/{0}/0_singlestory/pricea_sort/\".format(zipcode)\n",
    "    else:\n",
    "        url = \"https://www.zillow.com/homes/for_sale/{0}_rb/?fromHomePage=true&shouldFireSellPageImplicitClaimGA=false&fromHomePageTab=buy\".format(\n",
    "            zipcode)\n",
    "\n",
    "    for i in range(5):\n",
    "        # try:\n",
    "        headers = {\n",
    "            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'accept-encoding': 'gzip, deflate, sdch, br',\n",
    "            'accept-language': 'en-GB,en;q=0.8,en-US;q=0.6,ml;q=0.4',\n",
    "            'cache-control': 'max-age=0',\n",
    "            'upgrade-insecure-requests': '1',\n",
    "            'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        print(response.status_code)\n",
    "        parser = html.fromstring(response.text)\n",
    "        search_results = parser.xpath(\"//div[@id='search-results']//article\")\n",
    "        properties_list = []\n",
    "\n",
    "        for properties in search_results:\n",
    "            raw_address = properties.xpath(\".//span[@itemprop='address']//span[@itemprop='streetAddress']//text()\")\n",
    "            raw_city = properties.xpath(\".//span[@itemprop='address']//span[@itemprop='addressLocality']//text()\")\n",
    "            raw_state = properties.xpath(\".//span[@itemprop='address']//span[@itemprop='addressRegion']//text()\")\n",
    "            raw_postal_code = properties.xpath(\".//span[@itemprop='address']//span[@itemprop='postalCode']//text()\")\n",
    "            raw_price = properties.xpath(\".//span[@class='zsg-photo-card-price']//text()\")\n",
    "            raw_info = properties.xpath(\".//span[@class='zsg-photo-card-info']//text()\")\n",
    "            raw_broker_name = properties.xpath(\".//span[@class='zsg-photo-card-broker-name']//text()\")\n",
    "            url = properties.xpath(\".//a[contains(@class,'overlay-link')]/@href\")\n",
    "            raw_title = properties.xpath(\".//h4//text()\")\n",
    "\n",
    "            address = ' '.join(' '.join(raw_address).split()) if raw_address else None\n",
    "            city = ''.join(raw_city).strip() if raw_city else None\n",
    "            state = ''.join(raw_state).strip() if raw_state else None\n",
    "            postal_code = ''.join(raw_postal_code).strip() if raw_postal_code else None\n",
    "            price = ''.join(raw_price).strip() if raw_price else None\n",
    "            info = ' '.join(' '.join(raw_info).split()).replace(u\"\\xb7\", ',')\n",
    "            broker = ''.join(raw_broker_name).strip() if raw_broker_name else None\n",
    "            title = ''.join(raw_title) if raw_title else None\n",
    "            property_url = \"https://www.zillow.com\" + url[0] if url else None\n",
    "            is_forsale = properties.xpath('.//span[@class=\"zsg-icon-for-sale\"]')\n",
    "            properties = {\n",
    "                'address': address,\n",
    "                'city': city,\n",
    "                'state': state,\n",
    "                'postal_code': postal_code,\n",
    "                'price': price,\n",
    "                'facts and features': info,\n",
    "                'real estate provider': broker,\n",
    "                'url': property_url,\n",
    "                'title': title\n",
    "            }\n",
    "            if is_forsale:\n",
    "                properties_list.append(properties)\n",
    "        return properties_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_sf_area_codes(output_folder: str, zipcodes: list):\n",
    "    \"\"\"Scrape from all SF zip codes\"\"\"\n",
    "    sort = 'newest'\n",
    "    for zipcode in zipcodes:\n",
    "        print (\"Fetching data for %s\" % (zipcode))\n",
    "        scraped_data = parse(str(zipcode), sort)\n",
    "        print (\"Writing data to output file\")\n",
    "        with open(f\"{output_folder}/properties-{zipcode}.csv\", 'wb')as csvfile:\n",
    "            fieldnames = ['title', 'address', 'city', 'state', 'postal_code', 'price', 'facts and features',\n",
    "                          'real estate provider', 'url']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for row in scraped_data:\n",
    "                writer.writerow(row)\n",
    "def do_scraping(output_folder: str, zipcodes: list):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    scrape_all_sf_area_codes(output_folder=output_folder, zipcodes=zipcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 94102\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94104\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94103\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94105\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94108\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94107\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94110\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94109\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94112\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94111\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94115\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94114\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94117\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94116\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94118\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94121\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94123\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94122\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94124\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94127\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94126\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94129\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94131\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94133\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94132\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94134\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94139\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94143\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94146\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94151\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94159\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94158\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94188\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94177\n",
      "200\n",
      "Writing data to output file\n"
     ]
    }
   ],
   "source": [
    "data_dir = './scraped_data'\n",
    "do_scraping(output_folder=data_dir, zipcodes=SF_ZIPCODES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data is saved to a .csv for each zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "properties-94102.csv\n",
      "properties-94103.csv\n",
      "properties-94104.csv\n",
      "properties-94105.csv\n",
      "properties-94107.csv\n",
      "properties-94108.csv\n",
      "properties-94109.csv\n",
      "properties-94110.csv\n",
      "properties-94111.csv\n",
      "properties-94112.csv\n",
      "properties-94114.csv\n",
      "properties-94115.csv\n",
      "properties-94116.csv\n",
      "properties-94117.csv\n",
      "properties-94118.csv\n",
      "properties-94121.csv\n",
      "properties-94122.csv\n",
      "properties-94123.csv\n",
      "properties-94124.csv\n",
      "properties-94126.csv\n",
      "properties-94127.csv\n",
      "properties-94129.csv\n",
      "properties-94131.csv\n",
      "properties-94132.csv\n",
      "properties-94133.csv\n",
      "properties-94134.csv\n",
      "properties-94139.csv\n",
      "properties-94143.csv\n",
      "properties-94146.csv\n",
      "properties-94151.csv\n",
      "properties-94158.csv\n",
      "properties-94159.csv\n",
      "properties-94177.csv\n",
      "properties-94188.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$data_dir\"\n",
    "ls $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and view data in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data ./scraped_data/*.csv\n",
      "Found a total of 481 data points\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>price</th>\n",
       "      <th>facts and features</th>\n",
       "      <th>real estate provider</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Construction</td>\n",
       "      <td>288 Pacific Ave # YWAK0X</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94111</td>\n",
       "      <td>$2,300,000+</td>\n",
       "      <td>2 bds , 3 ba , 1,207+ sqft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.zillow.com/community/288-pacific/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For Sale by Owner</td>\n",
       "      <td>1234 Sansome And Un</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94111</td>\n",
       "      <td>$800,000</td>\n",
       "      <td>3 bds , 2 ba , 1,000 sqft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.zillow.com/homedetails/1234-Sansom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Condo For Sale</td>\n",
       "      <td>101 Lombard St APT 303E</td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>CA</td>\n",
       "      <td>94111</td>\n",
       "      <td>$1,999,000</td>\n",
       "      <td>2 bds , 2 ba , -- sqft</td>\n",
       "      <td>Sotheby's International Realty - San Francisco...</td>\n",
       "      <td>https://www.zillow.com/homedetails/101-Lombard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Condo For Sale</td>\n",
       "      <td>288 Pacific Ave # 2A</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94111</td>\n",
       "      <td>$2,300,000</td>\n",
       "      <td>2 bds , 3 ba , 1,207 sqft</td>\n",
       "      <td>Pacific Union International Inc.</td>\n",
       "      <td>https://www.zillow.com/homedetails/288-Pacific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Condo For Sale</td>\n",
       "      <td>733 Front St UNIT 606</td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>CA</td>\n",
       "      <td>94111</td>\n",
       "      <td>$1,195,000</td>\n",
       "      <td>1 bd , 1 ba , 920 sqft</td>\n",
       "      <td>Climb Real Estate</td>\n",
       "      <td>https://www.zillow.com/homedetails/733-Front-S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                   address           city state  \\\n",
       "0   New Construction  288 Pacific Ave # YWAK0X  San Francisco    CA   \n",
       "1  For Sale by Owner       1234 Sansome And Un  San Francisco    CA   \n",
       "2     Condo For Sale   101 Lombard St APT 303E  SAN FRANCISCO    CA   \n",
       "3     Condo For Sale      288 Pacific Ave # 2A  San Francisco    CA   \n",
       "4     Condo For Sale     733 Front St UNIT 606  SAN FRANCISCO    CA   \n",
       "\n",
       "  postal_code        price          facts and features  \\\n",
       "0       94111  $2,300,000+  2 bds , 3 ba , 1,207+ sqft   \n",
       "1       94111     $800,000   3 bds , 2 ba , 1,000 sqft   \n",
       "2       94111   $1,999,000      2 bds , 2 ba , -- sqft   \n",
       "3       94111   $2,300,000   2 bds , 3 ba , 1,207 sqft   \n",
       "4       94111   $1,195,000      1 bd , 1 ba , 920 sqft   \n",
       "\n",
       "                                real estate provider  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  Sotheby's International Realty - San Francisco...   \n",
       "3                   Pacific Union International Inc.   \n",
       "4                                  Climb Real Estate   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.zillow.com/community/288-pacific/2...  \n",
       "1  https://www.zillow.com/homedetails/1234-Sansom...  \n",
       "2  https://www.zillow.com/homedetails/101-Lombard...  \n",
       "3  https://www.zillow.com/homedetails/288-Pacific...  \n",
       "4  https://www.zillow.com/homedetails/733-Front-S...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "def load_data_to_dataframe(data_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load all .csv files from data_dir and concatenate them into a single DataFrame.  \n",
    "    Args:\n",
    "        data_dir: path to data directory\n",
    "    Returns:\n",
    "        pd.DataFrame: all data from files in data_dir\n",
    "    Notes:\n",
    "        All duplicate rows will be discarded\n",
    "    \"\"\"\n",
    "    all_csvs = []\n",
    "    # load the csv files from all scraping runs\n",
    "    csv_filenames = os.path.join(data_dir, '*.csv')\n",
    "    print('loading data {csv_filenames}'.format(csv_filenames=csv_filenames))\n",
    "    for filename in glob.glob(csv_filenames):\n",
    "        all_csvs.append(pd.read_csv(filename))\n",
    "    # combine all dataframes together and drop any duplicate entries\n",
    "    df = pd.concat(all_csvs, ignore_index=True).drop_duplicates()\n",
    "    print(\"Found a total of {count} data points\".format(count=len(df)))\n",
    "    # save this combined dataframe as csv for safe keeping\n",
    "    df.to_csv(os.path.join(data_dir, 'all_data.csv'), index=False)\n",
    "    return df\n",
    "\n",
    "df = load_data_to_dataframe(data_dir=data_dir)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
